{
    "collab_server" : "",
    "contents" : "---\ntitle: \"HW1\"\nauthor: \"Jake VanCampen\"\ndate: \"`r format(Sys.Date(), '%b-%d-%Y')`\"\noutput: html_document\n---\n\n```{r echo = FALSE}\nknitr::opts_chunk$set(message = FALSE)\n```\n\n## Exploratory Data Analysis\n\nAn RNA-Seq dataset from two populations of threespine stickleback fish `HW_RNAseq.csv` were read it into R.\n\n```{r}\n# load tidyverse packages \nlibrary(tidyverse)\n\nRNAseq_raw <- read_csv('HW_RNAseq.csv',col_names = TRUE) \n```\n\nTo determing how the data were read in by the `{readr} read.csv()` function, the class of the dataset was observed with the `class()` funtion. Then, an initial look at the data.\n\n```{r}\nclass(RNAseq_raw)\nhead(RNAseq_raw)\n```\n\n\nIt looks like the data were read in as a tibble. That's good news, it will make the dataset easier to work with. The categorical variables seem to be listed first, followed by the response variables. It could be useful to generate a list of each.\n\n```{r}\nvars_categorical <- colnames(RNAseq_raw)[1:4]\nvars_categorical\n\nvars_response <- colnames(RNAseq_raw)[5:length(colnames(RNAseq_raw))]\nvars_response\n```\n\n\n### Tidy Data\n\nIt looks like there are 10 continuous variables (genes) that are described by these data. Before we can make histograms for each gene the data will need to be tidied such that each row is an observation and each column is a variable. Right now there are too many columns representing the same variable. To achieve this, the `tidyr` function `gather()` can be used to manipulate the data.frame to merge the gene variables. \n\n\n```{r}\n# load tidyr package\nlibrary(tidyr)\n\ndata_tidy <- gather(RNAseq_raw, gene, count, -SampleID, -Population, -Treatment, -Sex)\n\nhead(data_tidy)\n```\n\n\nOkay that looks better, now 'gene' is a categorical variable, and the associated 'counts' were still retained. This will make it easier to visualize the data. \n\n\n### Histograms\n\nTo visualize the gene counts, histograms can be made to show the distribution of counts for each gene using `ggplot`. \n\n\n```{r}\nggplot(data = data_tidy, mapping = aes(x = count, fill = gene))+\n  geom_histogram(binwidth = 10)+\n  facet_wrap(~gene, nrow = 2)+\n  theme(legend.position = \"none\")+ \n  ggtitle('Frequency of counts across 10 genes')+\n  ylab('Frequency')\n```\n\n\nTo perform z-transformation on the data, they can be mean centered and scaled using the `scale()` function. Histograms of the z-transformed counts for just two genes are plotted here.\n\n```{r}\n# Ceci n'est pas une pipe\nlibrary(magrittr)\n\nztrans <- data_tidy %>% \n  group_by(gene) %>%\n  do(mutate(., z_trans = scale(.$count,\n                               center = TRUE,\n                               scale = TRUE)))\n\nhead(ztrans)\n\n# plot all genes\nztrans %>% \n  ggplot(., aes(z_trans, fill = gene))+\n    geom_histogram()+ \n    facet_wrap('gene', nrow = 2)+\n    theme(legend.position = \"none\")+\n    ggtitle('Frequency of zscores across 10 genes')+\n    xlab('Z-Score')+\n    ylab('Frequency')\n\n# plot only two genes\nztrans %>% \n  filter(gene == 'Gene01' | gene == 'Gene02') %>%\n  ggplot(., aes(z_trans, fill = gene))+\n    geom_histogram()+ \n    facet_wrap('gene', nrow = 2)+\n    theme(legend.position = \"none\")+\n    ggtitle('Frequency of zscores for two genes')+\n    xlab('Z-Score')+\n    ylab('Frequency')\n```\n\n\nVery nice. Centering and scaling the data make it a lot easier to see the differences between counts faceted by gene.\n\n\n### Boxplots\n\nIt would also be interesting to see how these counts data are distributed with respect to other categorical variables. Let's visuallize this with box plots for the original data, as well as the Z-transformed data. \n\n\n```{r}\n\nggplot(data_tidy, aes(gene, count, fill = gene))+\n  geom_boxplot()+\n  facet_wrap(c('Sex', 'Treatment', 'Population'), nrow = 2)+\n  theme(legend.position = \"none\")+\n  ggtitle('Counts for each gene across Sex, Population, and Treatment')+\n  coord_flip()\n  \n```\n\n\nSo much information in one figure! Let's take a look at the Z-transformed counts in this same fashion.\n\n```{r}\nggplot(ztrans, aes(gene, z_trans, fill = gene))+\n  geom_boxplot()+\n  facet_wrap(c('Sex', 'Treatment', 'Population'), nrow = 2)+\n  theme(legend.position = \"none\")+\n  ggtitle('Z-scores for each gene across Sex, Population, and Treatment')+\n  ylab('Z-score')+ \n  coord_flip()\n```\n\n\nIt's much easier to see the differences between data groupped by categorical variables when the data have been Z-transformed. \n\n\n### Summary Table\nlet's generate a table of summary statistics for each Population, Sex, and Treatment, at all the gene levels.\n\n```{r}\nlibrary(pander)\n\nsummary_sex <- data_tidy %>% \n  group_by(gene,Sex) %>%\n  summarise_at(., 'count', .funs = c(sex_mean = 'mean', sex_Var = 'var', sex_sd = 'sd'))\n\nsummary_pop <- data_tidy %>% \n  group_by(gene,Population) %>%\n  summarise_at(., 'count', .funs = c(Pop_mean = 'mean', Pop_Var = 'var', Pop_sd = 'sd'))\n\nsummary_trt <- data_tidy %>% \n  group_by(gene,Treatment) %>%\n  summarise_at(., 'count', .funs = c(trt_mean = 'mean', trt_Var = 'var', trt_sd = 'sd'))\n\nsummary_by_fctr <- cbind(summary_sex,summary_pop,summary_trt) %>% \n  .[,-c(6,11)]\n  \npander(summary_by_fctr)\n\n```\n\n\n## Standard Error and Confidence interval\n\nHere, the standard error and 95% confidence interval are calculated using the parametic, as well as bootstrap resampling approach. The results are compared in a table.\n\n\n```{r}\nlibrary(knitr)\n\n# parametric approach to standard error\nSE_para <- function(x) {\n  l_CI <- mean(x) - (sd(x)/sqrt(length(x)) * qt(0.975, (length(x)-1)))\n  u_CI <- mean(x) + (sd(x)/sqrt(length(x)) * qt(0.975, (length(x)-1)))\n  \n  return(data.frame(mean = mean(x), \n                    SE = sd(x)/sqrt(length(x)), \n                    p.ci.lower = l_CI, \n                    p.ci.upper = u_CI))\n}\n\n\n# Bootstrapped standard error of the mean\nSEM_boot <- function(x) {\nz <- NULL \nfor (i in 1:1000) {\n  xboot <- sample(x, 20, replace = T)\n  z[i] <- mean(xboot)\n}\nSEM <- sd(z)\nCI <- quantile(z,c(0.025,0.975))\nreturn(data.frame('SEM_bootstr' = SEM, \n                  bm.lower.ci = CI[1], \n                  bm.upper.ci = CI[2]))\n}\n\n# Bootstrapped standard error of the variance\nSEV_boot <- function(x) {\nz <- NULL \nfor (i in 1:1000) {\n  xboot <- sample(x, 20, replace = T)\n  z[i] <- var(xboot)\n}\nSEV <- sd(z)\nCI <- quantile(z,c(0.025,0.975))\nreturn(data.frame('SEV_bootstr' = SEV, \n                  bv.lower.ci = CI[1], \n                  bv.upper.ci = CI[2]))\n}\n\n\ndata_tidy %>% \n  group_by(gene) %>% \n  do(data.frame( \n    SE_para(.$count), \n    SEM_boot(.$count), \n    SEV_boot(.$count))\n    ) %>% kable(.,digits = 2,\n                align = 'c',\n                caption = 'Comparison of parametric and bootstrap resampling approaches to standard error')\n```\n\nThese results do show a decrease in the bootstrapped standard error compared to the parametric standard error, with a corresponding narrowing of the 95% confidence interval. The difference however, is fairly small and tells us that the data were more normally distributed than we may have expected and bootstrap resampling parameter estimation may not be necessary in this case.  \n\n## Douglas Fir at Mt. Pisgah \n\nPlot `Plots with X trees` vs. `Number of Trees in a Plot`, and determine how they are distributed. \n\n```{r}\ntrees <- tbl_df(data.frame('num_trees' = c(0:11), 'num_plots' = c(74,149,228,181,169,84,49,24,19,12,9,4)))\n\nggplot(trees, aes(num_trees, num_plots))+ \n  geom_point()+\n  xlab('Number of Trees in a Plot')+\n  ylab('Number of Plots with X trees')+ \n  ggtitle('Distribution of Plots with X number of Trees')+\n  theme_gray()\n```\n\nThese data look to be Poisson distributed! We can calculate the mean number of trees per plot and the variance in the number of trees per plot, which should approach the same number if the data are really Poisson distributed. \n\n```{r}\n# determine the total number of trees by unpacking these data\ntotal_trees <- rep(trees$num_trees, trees$num_plots)\n\n# calculate the mean and variance\nmean_trees <- mean(total_trees)\nvar(total_trees)\n```\n\nIt appears we need more support to test that these data are Poisson distributed, because the calculated mean and variance (of this small dataset) are unequal. Here, a maximum likelihood appraoch is used to estimate the parameter lambda using the poisson equaiton:\n$$P\\left( y = r \\right) = \\frac{{e^{ - \\lambda } \\lambda ^r }}{{r!}}$$\n\nThe 95% confidence interval of estimating this parameter is also calculated, and may tell how acceptable it is that the mean and variance are different. \n\n\n```{r}\nlambda <- seq(0,9,by = 0.001)\nln_y <- log((exp(1)^-lambda * lambda^mean_trees) / factorial(mean_trees))\n\n# log likelihood function\nlog_like <- data.frame(\"x\" = lambda, \"ln_y\" = ln_y)\n\n# maximum likelihood estimate\nsubset(log_like, ln_y == max(ln_y))\n\n# confidence interval\nCI <- subset(log_like, ln_y>=max(ln_y)-0.00192)\n\nggplot(log_like, aes(x, ln_y))+\n  geom_line()+\n  geom_vline(xintercept = c(min(CI$x), max(CI$x)), color = 'red') +\n  xlab('Lambda')+\n  ylab('Log likelihood of lambda')+\n  ggtitle('Maximum Likelihood Estimation of Lambda')\n```\n\nThe maximum likelihod estimate is 3, which is essentially the sample mean (3.094). The 95% confidence interval of this estimate was approximated at 1.92 log-likelihood units below the maximum, and shows that the sample variance (4.41) is outside the 95% confidence interval for the ML estimate of the parameter lambda. This means that we are not 95% confident that the data are Poisson distributed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1508790627109.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "704629967",
    "id" : "D8EA3E0A",
    "lastKnownWriteTime" : 1508434713,
    "last_content_update" : 1508434713,
    "path" : "~/Documents/Bi610/hw1/HW1.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}